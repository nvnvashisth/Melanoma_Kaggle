{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wtfml==0.0.2\r\n",
      "  Downloading wtfml-0.0.2-py3-none-any.whl (8.1 kB)\r\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in /opt/conda/lib/python3.7/site-packages (from wtfml==0.0.2) (0.22.2.post1)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.1->wtfml==0.0.2) (0.14.1)\r\n",
      "Requirement already satisfied: numpy>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.1->wtfml==0.0.2) (1.18.1)\r\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.1->wtfml==0.0.2) (1.4.1)\r\n",
      "Installing collected packages: wtfml\r\n",
      "Successfully installed wtfml-0.0.2\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Collecting pretrainedmodels\r\n",
      "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 58 kB 1.6 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (1.5.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (0.6.0a0+82fd1c8)\r\n",
      "Requirement already satisfied: munch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (2.5.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (4.45.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels) (0.18.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels) (1.18.1)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->pretrainedmodels) (5.4.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch->pretrainedmodels) (1.14.0)\r\n",
      "Building wheels for collected packages: pretrainedmodels\r\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60962 sha256=b8fc3ba908434900423ed3582365b5ee3e50f7cc77921dd931783d487c9777e9\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\r\n",
      "Successfully built pretrainedmodels\r\n",
      "Installing collected packages: pretrainedmodels\r\n",
      "Successfully installed pretrainedmodels-0.7.4\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install wtfml==0.0.2\n",
    "!pip install pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet_pytorch\r\n",
      "  Downloading efficientnet_pytorch-0.6.3.tar.gz (16 kB)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet_pytorch) (1.5.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (0.18.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (1.18.1)\r\n",
      "Building wheels for collected packages: efficientnet-pytorch\r\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-py3-none-any.whl size=12419 sha256=9950e1a37afd950f6d7f1a7a571c6723417bd673c1774b79009ae0f2476d7c68\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/90/6b/0c/f0ad36d00310e65390b0d4c9218ae6250ac579c92540c9097a\r\n",
      "Successfully built efficientnet-pytorch\r\n",
      "Installing collected packages: efficientnet-pytorch\r\n",
      "Successfully installed efficientnet-pytorch-0.6.3\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import albumentations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from wtfml.utils import EarlyStopping\n",
    "from wtfml.engine import Engine\n",
    "from wtfml.data_loaders.image import ClassificationLoader\n",
    "import efficientnet_pytorch\n",
    "import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEResnext50_32x4d(nn.Module):\n",
    "    def __init__(self, pretrained='imagenet'):\n",
    "        super(SEResnext50_32x4d, self).__init__()\n",
    "        \n",
    "        self.base_model = pretrainedmodels.__dict__[\n",
    "            \"se_resnext50_32x4d\"\n",
    "        ](pretrained=None)\n",
    "        if pretrained is not None:\n",
    "            self.base_model.load_state_dict(\n",
    "                torch.load(\n",
    "                    \"../input/pretrained-model-weights-pytorch/se_resnext50_32x4d-a260b3a4.pth\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.l0 = nn.Linear(2048, 1)\n",
    "    \n",
    "    def forward(self, image, targets):\n",
    "        batch_size, _, _, _ = image.shape\n",
    "        \n",
    "        x = self.base_model.features(image)\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n",
    "        \n",
    "        out = self.l0(x)\n",
    "        loss = nn.BCEWithLogitsLoss()(out, targets.view(-1, 1).type_as(x))\n",
    "\n",
    "        return out, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EfficientNet, self).__init__()\n",
    "        self.base_model = efficientnet_pytorch.EfficientNet.from_pretrained(\n",
    "            'efficientnet-b4'\n",
    "        )\n",
    "        self.base_model._fc = nn.Linear(\n",
    "            in_features=1792, \n",
    "            out_features=1, \n",
    "            bias=True\n",
    "        )\n",
    "        \n",
    "    def forward(self, image, targets):\n",
    "        out = self.base_model(image)\n",
    "        loss = nn.BCEWithLogitsLoss()(out, targets.view(-1, 1).type_as(out))\n",
    "        return out, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folds\n",
    "df = pd.read_csv(\"../input/siim-isic-melanoma-classification/train.csv\")\n",
    "df[\"kfold\"] = -1    \n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "y = df.target.values\n",
    "kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "for f, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n",
    "    df.loc[v_, 'kfold'] = f\n",
    "\n",
    "df.to_csv(\"train_folds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(fold):\n",
    "    training_data_path = \"../input/siic-isic-224x224-images/train/\"\n",
    "    df = pd.read_csv(\"/kaggle/working/train_folds.csv\")\n",
    "    device = \"cuda\"\n",
    "    epochs = 50\n",
    "    train_bs = 32\n",
    "    valid_bs = 16\n",
    "\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "#     model = SEResnext50_32x4d(pretrained=\"imagenet\")\n",
    "    model = EfficientNet()\n",
    "    model.to(device)\n",
    "\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    train_aug = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True),\n",
    "            albumentations.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15),\n",
    "            albumentations.Flip(p=0.5)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    valid_aug = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_images = df_train.image_name.values.tolist()\n",
    "    train_images = [os.path.join(training_data_path, i + \".png\") for i in train_images]\n",
    "    train_targets = df_train.target.values\n",
    "\n",
    "    valid_images = df_valid.image_name.values.tolist()\n",
    "    valid_images = [os.path.join(training_data_path, i + \".png\") for i in valid_images]\n",
    "    valid_targets = df_valid.target.values\n",
    "\n",
    "    train_dataset = ClassificationLoader(\n",
    "        image_paths=train_images,\n",
    "        targets=train_targets,\n",
    "        resize=None,\n",
    "        augmentations=train_aug,\n",
    "    )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=train_bs, shuffle=True, num_workers=4\n",
    "    )\n",
    "\n",
    "    valid_dataset = ClassificationLoader(\n",
    "        image_paths=valid_images,\n",
    "        targets=valid_targets,\n",
    "        resize=None,\n",
    "        augmentations=valid_aug,\n",
    "    )\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=valid_bs, shuffle=False, num_workers=4\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        patience=3,\n",
    "        threshold=0.001,\n",
    "        mode=\"max\"\n",
    "    )\n",
    "\n",
    "    es = EarlyStopping(patience=5, mode=\"max\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = Engine.train(train_loader, model, optimizer, device=device)\n",
    "        predictions, valid_loss = Engine.evaluate(\n",
    "            valid_loader, model, device=device\n",
    "        )\n",
    "        predictions = np.vstack((predictions)).ravel()\n",
    "        auc = metrics.roc_auc_score(valid_targets, predictions)\n",
    "        print(f\"Epoch = {epoch}, AUC = {auc}\")\n",
    "        scheduler.step(auc)\n",
    "\n",
    "        es(auc, model, model_path=f\"model_fold_{fold}.bin\")\n",
    "        if es.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(fold):\n",
    "    test_data_path = \"../input/siic-isic-224x224-images/test/\"\n",
    "    df = pd.read_csv(\"../input/siim-isic-melanoma-classification/test.csv\")\n",
    "    device = \"cuda\"\n",
    "    model_path=f\"model_fold_{fold}.bin\"\n",
    "\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    aug = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    images = df.image_name.values.tolist()\n",
    "    images = [os.path.join(test_data_path, i + \".png\") for i in images]\n",
    "    targets = np.zeros(len(images))\n",
    "\n",
    "    test_dataset = ClassificationLoader(\n",
    "        image_paths=images,\n",
    "        targets=targets,\n",
    "        resize=None,\n",
    "        augmentations=aug,\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=16, shuffle=False, num_workers=4\n",
    "    )\n",
    "\n",
    "#     model = SEResnext50_32x4d(pretrained=None)\n",
    "    model = EfficientNet()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "\n",
    "    predictions = Engine.predict(test_loader, model, device=device)\n",
    "    predictions = np.vstack((predictions)).ravel()\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth\" to /root/.cache/torch/checkpoints/efficientnet-b4-6ed6700e.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09241ca20034668b1b9c9def43843af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=77999237.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:41<00:00,  2.42it/s, loss=0.1]\n",
      "100%|██████████| 415/415 [00:33<00:00, 12.51it/s, loss=0.0755]\n",
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, AUC = 0.8569935382041696\n",
      "Validation score improved (-inf --> 0.8569935382041696). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:40<00:00,  2.43it/s, loss=0.0654]\n",
      "100%|██████████| 415/415 [00:31<00:00, 13.10it/s, loss=0.0738]\n",
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, AUC = 0.8646423820797765\n",
      "Validation score improved (0.8569935382041696 --> 0.8646423820797765). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:40<00:00,  2.43it/s, loss=0.0568]\n",
      "100%|██████████| 415/415 [00:32<00:00, 12.94it/s, loss=0.0715]\n",
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, AUC = 0.8826030492953215\n",
      "Validation score improved (0.8646423820797765 --> 0.8826030492953215). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:39<00:00,  2.44it/s, loss=0.0473]\n",
      "100%|██████████| 415/415 [00:32<00:00, 12.80it/s, loss=0.0795]\n",
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3, AUC = 0.8453620430882683\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:40<00:00,  2.44it/s, loss=0.0402]\n",
      "100%|██████████| 415/415 [00:32<00:00, 12.76it/s, loss=0.0833]\n",
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, AUC = 0.8884227361720064\n",
      "Validation score improved (0.8826030492953215 --> 0.8884227361720064). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:39<00:00,  2.44it/s, loss=0.03]\n",
      "100%|██████████| 415/415 [00:31<00:00, 13.23it/s, loss=0.0955]\n",
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, AUC = 0.8342223062610219\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:39<00:00,  2.44it/s, loss=0.0234]\n",
      "100%|██████████| 415/415 [00:31<00:00, 13.12it/s, loss=0.0966]\n",
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6, AUC = 0.8406650620508356\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 415/415 [00:31<00:00, 13.30it/s, loss=0.0736]\n",
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, AUC = 0.8523874105350151\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:39<00:00,  2.44it/s, loss=0.0485]\n",
      "100%|██████████| 415/415 [00:32<00:00, 12.80it/s, loss=0.0806]\n",
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3, AUC = 0.87248425257336\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:40<00:00,  2.44it/s, loss=0.102]\n",
      "100%|██████████| 829/829 [05:39<00:00,  2.44it/s, loss=0.0379]\n",
      "100%|██████████| 829/829 [05:38<00:00,  2.45it/s, loss=0.0265]\n",
      "100%|██████████| 415/415 [00:32<00:00, 12.77it/s, loss=0.0831]\n",
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6, AUC = 0.9121935395752238\n",
      "Validation score improved (0.907912155453643 --> 0.9121935395752238). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:39<00:00,  2.44it/s, loss=0.104]\n",
      "100%|██████████| 829/829 [05:38<00:00,  2.45it/s, loss=0.0398]\n",
      "100%|██████████| 415/415 [00:31<00:00, 12.99it/s, loss=0.0678]\n",
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, AUC = 0.8830722477003976\n",
      "Validation score improved (-inf --> 0.8830722477003976). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:40<00:00,  2.44it/s, loss=0.0642]\n",
      "100%|██████████| 829/829 [05:39<00:00,  2.44it/s, loss=0.0227]\n",
      "100%|██████████| 415/415 [00:32<00:00, 12.86it/s, loss=0.1]\n",
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6, AUC = 0.8693402991190331\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 150/829 [01:02<04:36,  2.45it/s, loss=0.0211]"
     ]
    }
   ],
   "source": [
    "train(0)\n",
    "train(1)\n",
    "train(2)\n",
    "train(3)\n",
    "train(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [00:53<00:00, 12.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [00:51<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [00:51<00:00, 13.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [00:50<00:00, 13.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [00:51<00:00, 13.43it/s]\n"
     ]
    }
   ],
   "source": [
    "p1 = predict(0)\n",
    "p2 = predict(1)\n",
    "p3 = predict(2)\n",
    "p4 = predict(3)\n",
    "p5 = predict(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (p1 + p2 + p3 + p4 + p5) / 5\n",
    "sample = pd.read_csv(\"../input/siim-isic-melanoma-classification/sample_submission.csv\")\n",
    "sample.loc[:, \"target\"] = predictions\n",
    "sample.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "161e6e1e476e47b59626b0528380c08b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ddbf4ef8abf41f9b9693cefb7d85360": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_161e6e1e476e47b59626b0528380c08b",
       "placeholder": "​",
       "style": "IPY_MODEL_c533962a099c46d98dd18a4bcdc1f894",
       "value": " 74.4M/74.4M [00:00&lt;00:00, 108MB/s]"
      }
     },
     "67d66fe3d1734330854b1a6fbb49f841": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "a57a14bba2064361aab8ac138d35aebc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_db245cefec1d4b5986123d2b9cdb803b",
       "max": 77999237.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_67d66fe3d1734330854b1a6fbb49f841",
       "value": 77999237.0
      }
     },
     "b8fc7f2767cd4678a49d54d587b2d129": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c533962a099c46d98dd18a4bcdc1f894": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "db245cefec1d4b5986123d2b9cdb803b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f09241ca20034668b1b9c9def43843af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a57a14bba2064361aab8ac138d35aebc",
        "IPY_MODEL_1ddbf4ef8abf41f9b9693cefb7d85360"
       ],
       "layout": "IPY_MODEL_b8fc7f2767cd4678a49d54d587b2d129"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
